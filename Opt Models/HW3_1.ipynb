{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fa619f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27548622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "School×Severity matrix saved to: Outcome/Q1_school_severity_matrix.xlsx\n",
      "Heatmap saved to: Outcome/Q1_heatmap_school_severity.png\n",
      "\n",
      "=== EDA Summary ===\n",
      "Schools: (20, 3) → saved to Outcome/Q1_schools_clean.csv\n",
      "Patients (long): (1600, 5) → saved to Outcome/Q1_patients_with_severity.csv\n",
      "School-level summary: (20, 8) → Outcome/Q1_school_summary.csv\n",
      "\n",
      "Historical capacity estimate per van:\n",
      "   van  daily_avg  monthly_capacity_est\n",
      "Van #0       16.0                   320\n",
      "Van #1       16.0                   320\n",
      "Saved to Outcome/Q1_capacity_estimate.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6d/nn3gll_n7f13x_pt18_lrtfc0000gn/T/ipykernel_4228/29267737.py:142: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  patients.assign(\n"
     ]
    }
   ],
   "source": [
    "def load_workbook(xlsx_path: Path):\n",
    "    assert xlsx_path.exists(), f\"File not found: {xlsx_path}\"\n",
    "    xls = pd.ExcelFile(xlsx_path)\n",
    "    return xls, xls.sheet_names\n",
    "\n",
    "\n",
    "def parse_schools(xlsx_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analysis of school locations.\n",
    "    \"\"\"\n",
    "    raw = pd.read_excel(xlsx_path, sheet_name=\"School Locations\", header=None)\n",
    "    tmp = raw.iloc[9:].reset_index(drop=True)\n",
    "    tmp.columns = [\"School\", \"X\", \"Y\"]\n",
    "    mask = tmp[\"School\"].astype(str).str.match(r\"School\\s+\\d+\")\n",
    "    df = (\n",
    "        tmp.loc[mask, [\"School\", \"X\", \"Y\"]]\n",
    "        .assign(school_id=lambda d: d[\"School\"].str.extract(r\"(\\d+)\").astype(int))\n",
    "        .drop(columns=[\"School\"])\n",
    "        .astype({\"X\": int, \"Y\": int})\n",
    "        .sort_values(\"school_id\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_patients_and_severity(xlsx_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analysis of patients and their severity levels.\n",
    "    \"\"\"\n",
    "    # 宽→长\n",
    "    patients_wide = pd.read_excel(xlsx_path, sheet_name=\"Case_PatientList\")\n",
    "    pat_long = (\n",
    "        patients_wide\n",
    "        .melt(var_name=\"school_col\", value_name=\"PATIENT\")\n",
    "        .dropna(subset=[\"PATIENT\"])\n",
    "        .assign(school=lambda d: d[\"school_col\"].str.extract(r\"#(\\d+)\").astype(int))\n",
    "        .drop(columns=[\"school_col\"])\n",
    "    )\n",
    "\n",
    "    severity_tbl = pd.read_excel(xlsx_path, sheet_name=\"Case_PatientSeverity\")\n",
    "\n",
    "    # 严重度映射（结合数据中出现的标签）\n",
    "    sev_map = {\n",
    "        \"Intermittent\": 1,\n",
    "        \"MildIntermittent\": 1,\n",
    "        \"MildPersistent\": 2,\n",
    "        \"ModeratePersistent\": 3,\n",
    "        \"SeverePersistent\": 4,\n",
    "    }\n",
    "\n",
    "    patients = (\n",
    "        pat_long.merge(severity_tbl, on=\"PATIENT\", how=\"left\")\n",
    "        .assign(\n",
    "            pid=lambda d: d[\"PATIENT\"].str.extract(r\"(\\d+)\").astype(int),\n",
    "            sev_weight=lambda d: d[\"SEVERITY\"].map(sev_map).fillna(2).astype(int),\n",
    "        )\n",
    "        [[\"pid\", \"PATIENT\", \"school\", \"SEVERITY\", \"sev_weight\"]]\n",
    "        .sort_values([\"school\", \"pid\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return patients\n",
    "\n",
    "\n",
    "def build_school_summary(schools: pd.DataFrame, patients: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    School-level summary: school_id, X, Y, num_patients, MildIntermittent, MildPersistent, ModeratePersistent, SeverePersistent\n",
    "    其中各严重度列为该校患者数。\n",
    "    \"\"\"\n",
    "    counts = patients.groupby(\"school\")[\"pid\"].count().rename(\"num_patients\").reset_index()\n",
    "\n",
    "    sev_dist = (\n",
    "        patients.pivot_table(\n",
    "            index=\"school\", columns=\"SEVERITY\", values=\"pid\", aggfunc=\"count\", fill_value=0\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    df = (\n",
    "        schools.merge(counts, left_on=\"school_id\", right_on=\"school\", how=\"left\")\n",
    "        .merge(sev_dist, left_on=\"school_id\", right_on=\"school\", how=\"left\")\n",
    "        .drop(columns=[\"school_x\", \"school_y\"], errors=\"ignore\")\n",
    "        .rename(columns={\"school_id\": \"school\"})\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    if \"num_patients\" in df.columns:\n",
    "        df[\"num_patients\"] = df[\"num_patients\"].astype(int)\n",
    "\n",
    "    cols = [\"school\", \"X\", \"Y\", \"num_patients\"]\n",
    "    other_cols = [c for c in df.columns if c not in cols]\n",
    "    df = df[cols + other_cols].sort_values(\"school\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def estimate_capacity_from_appointments(xlsx_path: Path, sheet_names) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get historical capacity estimates from appointment sheets.\n",
    "    \"\"\"\n",
    "    app_sheets = [s for s in sheet_names if s.startswith(\"Case_SCH#\")]\n",
    "    apps = []\n",
    "    for s in app_sheets:\n",
    "        sid = int(s.split(\"#\")[1].split(\"_\")[0])\n",
    "        df = pd.read_excel(xlsx_path, sheet_name=s)\n",
    "        df[\"school\"] = sid\n",
    "        apps.append(df)\n",
    "    if not apps:\n",
    "        return pd.DataFrame(columns=[\"van\", \"daily_avg\", \"monthly_capacity_est\"])\n",
    "\n",
    "    apps = pd.concat(apps, ignore_index=True)\n",
    "    apps[\"APP DATE\"] = pd.to_datetime(apps[\"APP DATE\"], errors=\"coerce\")\n",
    "    apps[\"VAN\"] = apps[\"VAN\"].astype(str)\n",
    "\n",
    "    daily = apps.groupby([\"VAN\", \"APP DATE\"]).size().reset_index(name=\"appointments\")\n",
    "    cap_daily = daily.groupby(\"VAN\")[\"appointments\"].mean().round(2)\n",
    "    cap_monthly = (cap_daily * 20).round(0).astype(\"Int64\")\n",
    "\n",
    "    cap_summary = (\n",
    "        pd.DataFrame({\"daily_avg\": cap_daily, \"monthly_capacity_est\": cap_monthly})\n",
    "        .reset_index()\n",
    "        .rename(columns={\"VAN\": \"van\"})\n",
    "        .sort_values(\"van\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return cap_summary\n",
    "\n",
    "def export_school_severity_matrix(\n",
    "    patients: pd.DataFrame,\n",
    "    out_dir: Path,\n",
    "    filename: str = \"Q1_school_severity_matrix.xlsx\",\n",
    "    heatmap_png: str = \"Q1_heatmap_school_severity.png\",\n",
    "):\n",
    "    \"\"\"\n",
    "    return: (matrix DataFrame, heatmap PNG path)\n",
    "    \"\"\"\n",
    " \n",
    "    sev_order = [\"MildIntermittent\", \"MildPersistent\",\n",
    "                 \"ModeratePersistent\", \"SeverePersistent\"]\n",
    "\n",
    "    # 计数矩阵\n",
    "    mat = (\n",
    "        patients.assign(\n",
    "            SEVERITY=pd.Categorical(patients[\"SEVERITY\"], categories=sev_order, ordered=True)\n",
    "        )\n",
    "        .pivot_table(index=\"school\", columns=\"SEVERITY\", values=\"pid\",\n",
    "                     aggfunc=\"count\", fill_value=0)\n",
    "        .sort_index()\n",
    "    )\n",
    " \n",
    "    xlsx_path = out_dir / filename\n",
    "    with pd.ExcelWriter(xlsx_path) as writer:\n",
    "        mat.to_excel(writer, sheet_name=\"counts\")\n",
    "        (mat.sum(axis=1).rename(\"Total_by_school\")\n",
    "         .to_frame().to_excel(writer, sheet_name=\"totals_by_school\"))\n",
    "        (mat.sum(axis=0).rename(\"Total_by_severity\")\n",
    "         .to_frame().to_excel(writer, sheet_name=\"totals_by_severity\"))\n",
    " \n",
    "    plt.figure(figsize=(1.2 * max(6, len(sev_order)) + 2,\n",
    "                        0.38 * max(6, len(mat.index)) + 2))\n",
    "    ax = sns.heatmap(mat, annot=True, fmt=\"d\", cbar=True)\n",
    "    ax.set_xlabel(\"Severity\")\n",
    "    ax.set_ylabel(\"School\")\n",
    "    ax.set_title(\"Patients per School by Severity\")\n",
    "    heatmap_path = out_dir / heatmap_png\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(heatmap_path, dpi=160, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    return mat, heatmap_path\n",
    "\n",
    "def main():\n",
    " \n",
    "    DATA_XLSX = Path(\"IEOR4004_HW3_MobileCareData.xlsx\")  \n",
    "    OUT_DIR = Path(\"Outcome\")                                       \n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    " \n",
    "\n",
    "    xls, sheet_names = load_workbook(DATA_XLSX)\n",
    "\n",
    "    # 1) 学校坐标\n",
    "    schools = parse_schools(DATA_XLSX)\n",
    "\n",
    "    # 2) 患者 + 严重度\n",
    "    patients = parse_patients_and_severity(DATA_XLSX)\n",
    "\n",
    "    # 3) 学校层汇总\n",
    "    school_summary = build_school_summary(schools, patients)\n",
    "\n",
    "    # 4) 历史容量估计（每车每日均值 & 月容量）\n",
    "    capacity = estimate_capacity_from_appointments(DATA_XLSX, sheet_names)\n",
    "\n",
    "    # 5) 导出 CSV\n",
    "    schools.to_csv(OUT_DIR / \"Q1_schools_clean.csv\", index=False)\n",
    "    patients.to_csv(OUT_DIR / \"Q1_patients_with_severity.csv\", index=False)\n",
    "    school_summary.to_csv(OUT_DIR / \"Q1_school_summary.csv\", index=False)\n",
    "    capacity.to_csv(OUT_DIR / \"Q1_capacity_estimate.csv\", index=False)\n",
    "\n",
    "    # 5.1) 学校 × 严重度矩阵\n",
    "    mat, heatmap_path = export_school_severity_matrix(patients, OUT_DIR)\n",
    "    print(f\"\\nSchool×Severity matrix saved to: {OUT_DIR / 'Q1_school_severity_matrix.xlsx'}\")\n",
    "    print(f\"Heatmap saved to: {heatmap_path}\")\n",
    "\n",
    "    print(\"\\n=== EDA Summary ===\")\n",
    "    print(f\"Schools: {schools.shape} → saved to {OUT_DIR / 'Q1_schools_clean.csv'}\")\n",
    "    print(f\"Patients (long): {patients.shape} → saved to {OUT_DIR / 'Q1_patients_with_severity.csv'}\")\n",
    "    print(f\"School-level summary: {school_summary.shape} → {OUT_DIR / 'Q1_school_summary.csv'}\")\n",
    "    print(\"\\nHistorical capacity estimate per van:\")\n",
    "    if len(capacity) > 0:\n",
    "        print(capacity.to_string(index=False))\n",
    "        print(f\"Saved to {OUT_DIR / 'Q1_capacity_estimate.csv'}\")\n",
    "    else:\n",
    "        print(\"No appointment sheets found (Case_SCH#k_APPS).\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d933fd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved Figures]\n",
      " - Outcome/Q1_fig_patients_per_school.png\n",
      " - Outcome/Q1_fig_severity_stack.png\n",
      " - Outcome/Q1_fig_school_locations.png\n",
      " - Outcome/Q1_fig_capacity_per_van.png\n",
      " - Outcome/Q1_fig_weighted_severity_per_school.png\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# Q1 Visualization (Append)\n",
    "# ===========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_DIR = Path(\"Outcome\") \n",
    "schools_csv = OUT_DIR / \"Q1_schools_clean.csv\"\n",
    "patients_csv = OUT_DIR / \"Q1_patients_with_severity.csv\"\n",
    "school_summary_csv = OUT_DIR / \"Q1_school_summary.csv\"\n",
    "capacity_csv = OUT_DIR / \"Q1_capacity_estimate.csv\"\n",
    " \n",
    "if \"schools\" not in globals():\n",
    "    schools = pd.read_csv(schools_csv)\n",
    "if \"patients\" not in globals():\n",
    "    patients = pd.read_csv(patients_csv)\n",
    "if \"school_summary\" not in globals():\n",
    "    school_summary = pd.read_csv(school_summary_csv)\n",
    "if \"capacity\" not in globals():\n",
    "    capacity = pd.read_csv(capacity_csv)\n",
    "\n",
    "fig1 = plt.figure(figsize=(10, 4))\n",
    "plt.bar(school_summary[\"school\"], school_summary[\"num_patients\"])\n",
    "plt.xlabel(\"School ID\")\n",
    "plt.ylabel(\"Number of Patients\")\n",
    "plt.title(\"Patients per School\")\n",
    "plt.tight_layout()\n",
    "fig1_path = OUT_DIR / \"Q1_fig_patients_per_school.png\"\n",
    "plt.savefig(fig1_path, dpi=160, bbox_inches=\"tight\")\n",
    "plt.close(fig1)\n",
    " \n",
    "sev_cols_all = [\"Intermittent\", \"MildIntermittent\", \"MildPersistent\", \"ModeratePersistent\", \"SeverePersistent\"]\n",
    "sev_cols = [c for c in sev_cols_all if c in school_summary.columns]\n",
    "\n",
    "fig2 = plt.figure(figsize=(12, 5))\n",
    "bottom = np.zeros(len(school_summary))\n",
    "for col in sev_cols:\n",
    "    vals = school_summary[col].values\n",
    "    plt.bar(school_summary[\"school\"], vals, bottom=bottom, label=col)\n",
    "    bottom = bottom + vals\n",
    "plt.xlabel(\"School ID\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Severity Composition per School (Counts)\")\n",
    "plt.legend(loc=\"upper right\", ncol=2, fontsize=8)\n",
    "plt.tight_layout()\n",
    "fig2_path = OUT_DIR / \"Q1_fig_severity_stack.png\"\n",
    "plt.savefig(fig2_path, dpi=160, bbox_inches=\"tight\")\n",
    "plt.close(fig2)\n",
    " \n",
    "fig3 = plt.figure(figsize=(5, 5))\n",
    "plt.scatter(schools[\"X\"], schools[\"Y\"])\n",
    "for _, r in schools.iterrows():\n",
    "    plt.text(r[\"X\"], r[\"Y\"], str(int(r[\"school_id\"])), fontsize=8)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"School Locations (Grid Coordinates)\")\n",
    "plt.tight_layout()\n",
    "fig3_path = OUT_DIR / \"Q1_fig_school_locations.png\"\n",
    "plt.savefig(fig3_path, dpi=160, bbox_inches=\"tight\")\n",
    "plt.close(fig3)\n",
    " \n",
    "fig4 = plt.figure(figsize=(5, 4))\n",
    "plt.bar(capacity[\"van\"], capacity[\"daily_avg\"])\n",
    "plt.xlabel(\"Van\")\n",
    "plt.ylabel(\"Daily Avg Appointments\")\n",
    "plt.title(\"Historical Daily Capacity per Van\")\n",
    "plt.tight_layout()\n",
    "fig4_path = OUT_DIR / \"Q1_fig_capacity_per_van.png\"\n",
    "plt.savefig(fig4_path, dpi=160, bbox_inches=\"tight\")\n",
    "plt.close(fig4)\n",
    " \n",
    "if \"sev_weight\" in patients.columns:\n",
    "    wsum = patients.groupby(\"school\")[\"sev_weight\"].sum().reset_index(name=\"weighted_sum\")\n",
    "    fig5 = plt.figure(figsize=(10, 4))\n",
    "    plt.bar(wsum[\"school\"], wsum[\"weighted_sum\"])\n",
    "    plt.xlabel(\"School ID\")\n",
    "    plt.ylabel(\"Weighted Severity Sum\")\n",
    "    plt.title(\"Weighted Severity Sum per School\")\n",
    "    plt.tight_layout()\n",
    "    fig5_path = OUT_DIR / \"Q1_fig_weighted_severity_per_school.png\"\n",
    "    plt.savefig(fig5_path, dpi=160, bbox_inches=\"tight\")\n",
    "    plt.close(fig5)\n",
    "else:\n",
    "    fig5_path = None\n",
    "\n",
    "print(\"[Saved Figures]\")\n",
    "print(f\" - {fig1_path}\")\n",
    "print(f\" - {fig2_path}\")\n",
    "print(f\" - {fig3_path}\")\n",
    "print(f\" - {fig4_path}\")\n",
    "if fig5_path:\n",
    "    print(f\" - {fig5_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff00018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2722020\n",
      "Academic license - for non-commercial use only - expires 2026-10-14\n",
      "Set parameter OutputFlag to value 1\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (mac64[arm] - Darwin 25.0.0 25A354)\n",
      "\n",
      "CPU model: Apple M4\n",
      "Thread count: 10 physical cores, 10 logical processors, using up to 10 threads\n",
      "\n",
      "Optimize a model with 6422 rows, 4840 columns and 16040 nonzeros\n",
      "Model fingerprint: 0x579d41c6\n",
      "Variable types: 0 continuous, 4840 integer (4840 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 4e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 3e+02]\n",
      "Found heuristic solution: objective -0.0000000\n",
      "Presolve removed 1620 rows and 1620 columns\n",
      "Presolve time: 0.02s\n",
      "Presolved: 4802 rows, 3220 columns, 12800 nonzeros\n",
      "Variable types: 0 continuous, 3220 integer (3220 binary)\n",
      "Found heuristic solution: objective 1417.0000000\n",
      "\n",
      "Root relaxation: objective 1.923000e+03, 2741 iterations, 0.07 seconds (0.30 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "H    0     0                    1923.0000000 1923.00000  0.00%     -    0s\n",
      "     0     0 1923.00000    0   23 1923.00000 1923.00000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (2741 simplex iterations) in 0.09 seconds (0.34 work units)\n",
      "Thread count was 10 (of 10 available processors)\n",
      "\n",
      "Solution count 3: 1923 1417 -0 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.923000000000e+03, best bound 1.923000000000e+03, gap 0.0000%\n",
      "\n",
      "Optimal weighted coverage = 1923\n",
      "Van monthly capacities: {'Van #0': 320, 'Van #1': 320}\n",
      "\n",
      "[Scheduled Patients by Severity]\n",
      "          SEVERITY  scheduled_count\n",
      "ModeratePersistent              469\n",
      "  SeverePersistent               87\n",
      "    MildPersistent               84\n",
      "Avg severity weight (scheduled): 3.005\n",
      "Saved: Outcome/scheduled_severity_counts_overall.csv\n",
      "Saved: Outcome/scheduled_severity_counts_by_van.csv\n",
      "Saved: Outcome/scheduled_severity_counts_by_van_school.csv\n",
      "Saved: Outcome/schools_assignment.csv\n",
      "Saved: Outcome/selected_patients.csv\n",
      "Saved: Outcome/schedule_summary_by_school.csv\n",
      "Saved figures:\n",
      "Outcome/fig_assignment_map.png\n",
      "Outcome/fig_assigned_counts_by_school.png\n",
      "Outcome/fig_weighted_sum_by_school.png\n",
      "Saved: Outcome/topk_schools_by_van.csv\n",
      "\n",
      "DONE. Provide these in your Results section:\n",
      "- Optimal objective (weighted coverage): 1923\n"
     ]
    }
   ],
   "source": [
    "# q1_optimal_schedule.py\n",
    "# Solve to optimality (Gurobi) and export a clear, interpretable monthly schedule.\n",
    "# Objective: maximize total weighted patients served under per-van monthly capacity.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from gurobipy import Model, GRB, quicksum\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "DATA_DIR = Path(\"Outcome\")  # <<<< change to your folder if needed\n",
    "OUT_DIR  = Path(\"Outcome\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SCHOOLS_CSV   = DATA_DIR / \"Q1_schools_clean.csv\"          # school_id, X, Y\n",
    "PATIENTS_CSV  = DATA_DIR / \"Q1_patients_with_severity.csv\" # pid, PATIENT, school, SEVERITY, sev_weight\n",
    "CAPACITY_CSV  = DATA_DIR / \"Q1_capacity_estimate.csv\"      # van, daily_avg, monthly_capacity_est\n",
    "\n",
    "VANS = [\"Van #0\", \"Van #1\"]  # fixed two vans\n",
    "\n",
    "# -------------------- Load data --------------------\n",
    "schools  = pd.read_csv(SCHOOLS_CSV)   # school_id, X, Y\n",
    "patients = pd.read_csv(PATIENTS_CSV)  # pid, PATIENT, school, SEVERITY, sev_weight\n",
    "capacity = pd.read_csv(CAPACITY_CSV)  # van, daily_avg, monthly_capacity_est\n",
    "\n",
    "# sets & maps\n",
    "S = sorted(schools[\"school_id\"].astype(int).tolist())\n",
    "P_all = patients[\"pid\"].astype(int).tolist()\n",
    "\n",
    "s_of_p = patients.set_index(\"pid\")[\"school\"].astype(int).to_dict()\n",
    "w      = patients.set_index(\"pid\")[\"sev_weight\"].astype(int).to_dict()\n",
    "severity_map = patients.set_index(\"pid\")[\"SEVERITY\"].to_dict()\n",
    "name_map     = patients.set_index(\"pid\")[\"PATIENT\"].to_dict()\n",
    "\n",
    "# van capacity (monthly)\n",
    "C = {row[\"van\"]: int(row[\"monthly_capacity_est\"]) for _, row in capacity.iterrows()}\n",
    "for v in VANS:\n",
    "    if v not in C:  # fallback if missing\n",
    "        C[v] = int(capacity[\"monthly_capacity_est\"].mean())\n",
    "\n",
    "# -------------------- Build MILP --------------------\n",
    "m = Model(\"MCF_MaxWeightedCoverage\")\n",
    "m.Params.OutputFlag = 1\n",
    "\n",
    "# decision variables\n",
    "x = {(s,v): m.addVar(vtype=GRB.BINARY, name=f\"x[{s},{v}]\") for s in S for v in VANS}  # school->van\n",
    "y = {p:      m.addVar(vtype=GRB.BINARY, name=f\"y[{p}]\")     for p in P_all}           # patient served?\n",
    "z = {(p,v):  m.addVar(vtype=GRB.BINARY, name=f\"z[{p},{v}]\") for p in P_all for v in VANS}  # patient->van\n",
    "\n",
    "# objective\n",
    "m.setObjective(quicksum(w[p]*y[p] for p in P_all), GRB.MAXIMIZE)\n",
    "\n",
    "# constraints\n",
    "# (1) each school assigned to exactly one van\n",
    "for s in S:\n",
    "    m.addConstr(quicksum(x[(s,v)] for v in VANS) == 1, name=f\"one_van_per_school[{s}]\")\n",
    "\n",
    "# (2) y[p] = sum_v z[p,v] <= 1\n",
    "for p in P_all:\n",
    "    m.addConstr(y[p] == quicksum(z[(p,v)] for v in VANS), name=f\"y_def[{p}]\")\n",
    "    m.addConstr(y[p] <= 1, name=f\"y_le_one[{p}]\")\n",
    "\n",
    "# (3) link: patient can only go to van that serves their school\n",
    "for p in P_all:\n",
    "    s = s_of_p[p]\n",
    "    for v in VANS:\n",
    "        m.addConstr(z[(p,v)] <= x[(s,v)], name=f\"link[{p},{v}]\")\n",
    "\n",
    "# (4) van monthly capacity\n",
    "for v in VANS:\n",
    "    m.addConstr(quicksum(z[(p,v)] for p in P_all) <= C[v], name=f\"capacity[{v}]\")\n",
    "\n",
    "m.optimize()\n",
    "\n",
    "if m.Status != GRB.OPTIMAL:\n",
    "    raise RuntimeError(f\"Solve status != OPTIMAL (status={m.Status})\")\n",
    "\n",
    "print(f\"\\nOptimal weighted coverage = {m.ObjVal:.0f}\")\n",
    "print(\"Van monthly capacities:\", C)\n",
    "\n",
    "# -------------------- Extract solution --------------------\n",
    "assign = {(s,v): int(round(x[(s,v)].X)) for s in S for v in VANS}\n",
    "school_to_van = {s: (VANS[0] if assign[(s,VANS[0])]==1 else VANS[1]) for s in S}\n",
    "\n",
    "rows_pat = []\n",
    "for p in P_all:\n",
    "    if y[p].X > 0.5:\n",
    "        v_star = [v for v in VANS if z[(p,v)].X > 0.5]\n",
    "        v_use  = v_star[0] if v_star else None\n",
    "        rows_pat.append({\n",
    "            \"pid\": p,\n",
    "            \"PATIENT\": name_map[p],\n",
    "            \"school\": s_of_p[p],\n",
    "            \"van\": v_use,\n",
    "            \"SEVERITY\": severity_map.get(p, \"\"),\n",
    "            \"sev_weight\": int(w[p]),\n",
    "        })\n",
    "\n",
    "selected_patients = pd.DataFrame(rows_pat).sort_values([\"van\",\"school\",\"sev_weight\",\"pid\"], ascending=[True, True, False, True])\n",
    "\n",
    "rows_s = []\n",
    "for s in S:\n",
    "    v = school_to_van[s]\n",
    "    rows_s.append({\"school\": s, \"van\": v})\n",
    "schools_assignment = pd.DataFrame(rows_s).sort_values(\"school\")\n",
    "\n",
    "# per-school summary\n",
    "summary = (\n",
    "    selected_patients\n",
    "    .groupby([\"van\",\"school\"])[\"pid\"]\n",
    "    .count()\n",
    "    .rename(\"assigned_patients\")\n",
    "    .reset_index()\n",
    ")\n",
    "wsum = (\n",
    "    selected_patients\n",
    "    .groupby([\"van\",\"school\"])[\"sev_weight\"]\n",
    "    .sum()\n",
    "    .rename(\"weighted_sum\")\n",
    "    .reset_index()\n",
    ")\n",
    "schedule_summary_by_school = summary.merge(wsum, on=[\"van\",\"school\"], how=\"outer\").fillna(0).sort_values([\"van\",\"school\"])\n",
    "\n",
    "# -------------------- Export CSV --------------------\n",
    "schools_assignment_path = OUT_DIR / \"schools_assignment.csv\"\n",
    "selected_patients_path  = OUT_DIR / \"selected_patients.csv\"\n",
    "summary_path            = OUT_DIR / \"schedule_summary_by_school.csv\"\n",
    "\n",
    "schools_assignment.to_csv(schools_assignment_path, index=False)\n",
    "selected_patients.to_csv(selected_patients_path, index=False)\n",
    "schedule_summary_by_school.to_csv(summary_path, index=False)\n",
    "\n",
    "\n",
    "# ===== 追加：已安排（scheduled）病人按严重度的汇总 =====\n",
    "# 统一缺失标签\n",
    "selected_patients[\"SEVERITY\"] = selected_patients[\"SEVERITY\"].fillna(\"Unknown\")\n",
    "\n",
    "# 1) 全局：按严重度统计已安排的病人数\n",
    "sev_counts_overall = (\n",
    "    selected_patients\n",
    "    .groupby(\"SEVERITY\")[\"pid\"]\n",
    "    .count()\n",
    "    .rename(\"scheduled_count\")\n",
    "    .reset_index()\n",
    "    .sort_values(\"scheduled_count\", ascending=False)\n",
    ")\n",
    "sev_counts_overall_path = OUT_DIR / \"scheduled_severity_counts_overall.csv\"\n",
    "sev_counts_overall.to_csv(sev_counts_overall_path, index=False)\n",
    "\n",
    "# 2) 分车（van）+严重度：每辆车各严重度的已安排人数（透视表）\n",
    "sev_counts_by_van = (\n",
    "    selected_patients\n",
    "    .groupby([\"van\", \"SEVERITY\"])[\"pid\"]\n",
    "    .count()\n",
    "    .rename(\"scheduled_count\")\n",
    "    .reset_index()\n",
    "    .pivot(index=\"SEVERITY\", columns=\"van\", values=\"scheduled_count\")\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    "    .sort_index()\n",
    ")\n",
    "sev_counts_by_van_path = OUT_DIR / \"scheduled_severity_counts_by_van.csv\"\n",
    "sev_counts_by_van.to_csv(sev_counts_by_van_path)\n",
    "\n",
    "# 3) （可选）分车×分校×严重度：更细的明细表\n",
    "sev_counts_by_van_school = (\n",
    "    selected_patients\n",
    "    .groupby([\"van\", \"school\", \"SEVERITY\"])[\"pid\"]\n",
    "    .count()\n",
    "    .rename(\"scheduled_count\")\n",
    "    .reset_index()\n",
    "    .sort_values([\"van\", \"school\", \"SEVERITY\"])\n",
    ")\n",
    "sev_counts_by_van_school_path = OUT_DIR / \"scheduled_severity_counts_by_van_school.csv\"\n",
    "sev_counts_by_van_school.to_csv(sev_counts_by_van_school_path, index=False)\n",
    "\n",
    "# 控制台打印一个简洁汇总\n",
    "print(\"\\n[Scheduled Patients by Severity]\")\n",
    "print(sev_counts_overall.to_string(index=False))\n",
    "\n",
    "# （可选）算一个平均严重度，便于报告\n",
    "try:\n",
    "    avg_sev_among_scheduled = (\n",
    "        selected_patients[\"sev_weight\"].sum() / len(selected_patients)\n",
    "        if len(selected_patients) > 0 else 0.0\n",
    "    )\n",
    "    print(f\"Avg severity weight (scheduled): {avg_sev_among_scheduled:.3f}\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"Saved:\", sev_counts_overall_path)\n",
    "print(\"Saved:\", sev_counts_by_van_path)\n",
    "print(\"Saved:\", sev_counts_by_van_school_path)\n",
    "\n",
    "print(\"Saved:\", schools_assignment_path)\n",
    "print(\"Saved:\", selected_patients_path)\n",
    "print(\"Saved:\", summary_path)\n",
    "\n",
    "# -------------------- Visualizations --------------------\n",
    "# 1) School assignment map (scatter), label by school id, annotate van\n",
    "fig1 = plt.figure(figsize=(6,6))\n",
    "sch_plot = schools.merge(schools_assignment, left_on=\"school_id\", right_on=\"school\", how=\"left\")\n",
    "plt.scatter(sch_plot[\"X\"], sch_plot[\"Y\"])\n",
    "for _, r in sch_plot.iterrows():\n",
    "    label = f\"{int(r['school_id'])}\\n({r['van']})\"\n",
    "    plt.text(r[\"X\"], r[\"Y\"], label, fontsize=8)\n",
    "plt.xlabel(\"X\"); plt.ylabel(\"Y\"); plt.title(\"School-to-Van Assignment (Map)\")\n",
    "plt.tight_layout()\n",
    "fig1_path = OUT_DIR / \"fig_assignment_map.png\"\n",
    "plt.savefig(fig1_path, dpi=160, bbox_inches=\"tight\")\n",
    "plt.close(fig1)\n",
    "\n",
    "# 2) Assigned patients per school by van (side-by-side bars)\n",
    "wide_counts = schedule_summary_by_school.pivot(index=\"school\", columns=\"van\", values=\"assigned_patients\").fillna(0).reindex(S)\n",
    "fig2 = plt.figure(figsize=(10,4))\n",
    "ind = np.arange(len(wide_counts.index))\n",
    "width = 0.35\n",
    "vals0 = wide_counts[VANS[0]].values if VANS[0] in wide_counts.columns else np.zeros(len(ind))\n",
    "vals1 = wide_counts[VANS[1]].values if VANS[1] in wide_counts.columns else np.zeros(len(ind))\n",
    "plt.bar(ind - width/2, vals0, width, label=VANS[0])\n",
    "plt.bar(ind + width/2, vals1, width, label=VANS[1])\n",
    "plt.xticks(ind, wide_counts.index, rotation=0)\n",
    "plt.xlabel(\"School\"); plt.ylabel(\"Assigned Patients\"); plt.title(\"Assigned Patients per School (by Van)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "fig2_path = OUT_DIR / \"fig_assigned_counts_by_school.png\"\n",
    "plt.savefig(fig2_path, dpi=160, bbox_inches=\"tight\")\n",
    "plt.close(fig2)\n",
    "\n",
    "# 3) Weighted sum per school (by van)\n",
    "wide_w = schedule_summary_by_school.pivot(index=\"school\", columns=\"van\", values=\"weighted_sum\").fillna(0).reindex(S)\n",
    "fig3 = plt.figure(figsize=(10,4))\n",
    "ind = np.arange(len(wide_w.index))\n",
    "width = 0.35\n",
    "vals0 = wide_w[VANS[0]].values if VANS[0] in wide_w.columns else np.zeros(len(ind))\n",
    "vals1 = wide_w[VANS[1]].values if VANS[1] in wide_w.columns else np.zeros(len(ind))\n",
    "plt.bar(ind - width/2, vals0, width, label=VANS[0])\n",
    "plt.bar(ind + width/2, vals1, width, label=VANS[1])\n",
    "plt.xticks(ind, wide_w.index, rotation=0)\n",
    "plt.xlabel(\"School\"); plt.ylabel(\"Weighted Sum\"); plt.title(\"Weighted Coverage per School (by Van)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "fig3_path = OUT_DIR / \"fig_weighted_sum_by_school.png\"\n",
    "plt.savefig(fig3_path, dpi=160, bbox_inches=\"tight\")\n",
    "plt.close(fig3)\n",
    "\n",
    "# 4) Top-K schools for each van (by assigned count)\n",
    "K = 5\n",
    "tops = []\n",
    "for v in VANS:\n",
    "    dfv = schedule_summary_by_school[schedule_summary_by_school[\"van\"]==v].sort_values(\"assigned_patients\", ascending=False).head(K)\n",
    "    dfv = dfv.assign(rank=np.arange(1, len(dfv)+1))\n",
    "    tops.append(dfv)\n",
    "topk = pd.concat(tops, ignore_index=True)\n",
    "topk_path = OUT_DIR / \"topk_schools_by_van.csv\"\n",
    "topk.to_csv(topk_path, index=False)\n",
    "\n",
    "print(\"Saved figures:\")\n",
    "print(fig1_path)\n",
    "print(fig2_path)\n",
    "print(fig3_path)\n",
    "print(\"Saved:\", topk_path)\n",
    "\n",
    "print(\"\\nDONE. Provide these in your Results section:\")\n",
    "print(\"- Optimal objective (weighted coverage):\", int(round(m.ObjVal))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da21ec4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined figure: Outcome/fig_routes_combined.png\n"
     ]
    }
   ],
   "source": [
    "# routing_tsp_per_van_combined.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "from math import sqrt\n",
    " \n",
    "DATA_DIR = Path(\"Outcome\")   \n",
    "OUT_DIR  = Path(\"Outcome\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SCHOOLS_CSV  = DATA_DIR / \"Q1_schools_clean.csv\"   \n",
    "ASSIGN_CSV   = DATA_DIR / \"schools_assignment.csv\"    \n",
    "DIST_UNIT    = \"euclidean\" \n",
    "UNIT_SCALE   = 0.1           \n",
    "MAKE_CYCLE   = True    \n",
    "FIXED_START  = None         # \n",
    "VANS_ORDER   = [\"Van #0\", \"Van #1\"]   \n",
    "\n",
    "# ---------- Load ----------\n",
    "schools = pd.read_csv(SCHOOLS_CSV)   \n",
    "assign  = pd.read_csv(ASSIGN_CSV)       \n",
    "df = assign.merge(schools, left_on=\"school\", right_on=\"school_id\", how=\"left\")\n",
    "df = df[[\"school\", \"van\", \"X\", \"Y\"]].sort_values([\"van\",\"school\"]).reset_index(drop=True)\n",
    "\n",
    "# ---------- Distance helpers ----------\n",
    "def dist(a, b, metric=\"euclidean\", scale=1.0):\n",
    "    if metric == \"euclidean\":\n",
    "        d = sqrt((a[0]-b[0])**2 + (a[1]-b[1])**2)\n",
    "    elif metric == \"manhattan\":\n",
    "        d = abs(a[0]-b[0]) + abs(a[1]-b[1])\n",
    "    else:\n",
    "        raise ValueError(\"Unknown metric\")\n",
    "    return d * scale\n",
    "\n",
    "def build_complete_graph(nodes_xy, metric=\"euclidean\", scale=1.0):\n",
    "    G = nx.Graph()\n",
    "    for n, (x, y) in nodes_xy.items():\n",
    "        G.add_node(n, pos=(x, y))\n",
    "    ids = list(nodes_xy.keys())\n",
    "    for i in range(len(ids)):\n",
    "        for j in range(i+1, len(ids)):\n",
    "            u, v = ids[i], ids[j]\n",
    "            w = dist(nodes_xy[u], nodes_xy[v], metric, scale)\n",
    "            G.add_edge(u, v, weight=w)\n",
    "    return G\n",
    "\n",
    "def route_length(route, nodes_xy, metric=\"euclidean\", scale=1.0, cycle=True):\n",
    "    total = 0.0\n",
    "    for i in range(len(route)-1):\n",
    "        total += dist(nodes_xy[route[i]], nodes_xy[route[i+1]], metric, scale)\n",
    "    if cycle and len(route) > 1:\n",
    "        total += dist(nodes_xy[route[-1]], nodes_xy[route[0]], metric, scale)\n",
    "    return total\n",
    "\n",
    "def solve_tsp_sequence(nodes_xy, metric=\"euclidean\", scale=1.0, cycle=True, fixed_start=None):\n",
    "    if len(nodes_xy) <= 1:\n",
    "        return list(nodes_xy.keys())\n",
    "    G = build_complete_graph(nodes_xy, metric, scale)\n",
    "    tour = nx.approximation.traveling_salesman_problem(\n",
    "        G, weight=\"weight\", cycle=cycle, method=nx.approximation.christofides\n",
    "    )\n",
    "    if cycle and len(tour) > 1 and tour[0] == tour[-1]:\n",
    "        tour = tour[:-1]\n",
    "    # rotate to fixed start if provided; else use left-most as start for consistent labels\n",
    "    if fixed_start is None or fixed_start not in nodes_xy:\n",
    "        fixed_start = min(nodes_xy, key=lambda s: nodes_xy[s][0])\n",
    "    if fixed_start in tour:\n",
    "        idx = tour.index(fixed_start)\n",
    "        tour = tour[idx:] + tour[:idx]\n",
    "    return tour\n",
    "\n",
    "# ---------- Solve per van & export ----------\n",
    "all_routes = {}   # van -> {\"path\": [...], \"points\": {...}, \"length\": float}\n",
    "color_map  = {\"Van #0\": \"tab:blue\", \"Van #1\": \"tab:orange\"}\n",
    "\n",
    "for van, grp in df.groupby(\"van\"):\n",
    "    points = {int(r.school): (float(r.X), float(r.Y)) for _, r in grp.iterrows()}\n",
    "    if len(points) == 0:\n",
    "        continue\n",
    "    path = solve_tsp_sequence(points, metric=DIST_UNIT, scale=UNIT_SCALE, cycle=MAKE_CYCLE, fixed_start=FIXED_START)\n",
    "    L = route_length(path, points, metric=DIST_UNIT, scale=UNIT_SCALE, cycle=MAKE_CYCLE)\n",
    "    all_routes[van] = {\"path\": path, \"points\": points, \"length\": L}\n",
    "\n",
    "    # 导出 CSV\n",
    "    rows = []\n",
    "    cum = 0.0\n",
    "    for i in range(len(path)):\n",
    "        s = path[i]\n",
    "        step = 0.0 if i == 0 else dist(points[path[i-1]], points[s], DIST_UNIT, UNIT_SCALE)\n",
    "        cum += step\n",
    "        rows.append({\"order\": i+1, \"school\": s, \"x\": points[s][0], \"y\": points[s][1], \"step_dist\": step, \"cum_dist\": cum})\n",
    "    if MAKE_CYCLE and len(path) > 1:\n",
    "        back = dist(points[path[-1]], points[path[0]], DIST_UNIT, UNIT_SCALE)\n",
    "        rows.append({\"order\": len(path)+1, \"school\": path[0], \"x\": points[path[0]][0], \"y\": points[path[0]][1],\n",
    "                     \"step_dist\": back, \"cum_dist\": cum + back})\n",
    "    pd.DataFrame(rows).to_csv(OUT_DIR / (van.replace(\" \", \"\").lower() + \"_route.csv\"), index=False)\n",
    "\n",
    "    # 单独图（可保留）\n",
    "    xs = [points[s][0] for s in path] + ([points[path[0]][0]] if MAKE_CYCLE and len(path)>1 else [])\n",
    "    ys = [points[s][1] for s in path] + ([points[path[0]][1]] if MAKE_CYCLE and len(path)>1 else [])\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    plt.scatter([p[0] for p in points.values()], [p[1] for p in points.values()], color=color_map.get(van, None))\n",
    "    plt.plot(xs, ys, linewidth=2, color=color_map.get(van, None))\n",
    "    for i, s in enumerate(path, start=1):\n",
    "        plt.text(points[s][0], points[s][1], f\"{s}\\n#{i}\", fontsize=8, color=color_map.get(van, None))\n",
    "    plt.xlabel(\"X\"); plt.ylabel(\"Y\"); plt.title(f\"{van} - Shortest Route (approx. TSP)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / (van.replace(\" \", \"\").lower() + \"_route.png\"), dpi=160, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "# ---------- Combined figure ----------\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "\n",
    "# \n",
    "all_X = [float(r.X) for _, r in df.iterrows()]\n",
    "all_Y = [float(r.Y) for _, r in df.iterrows()]\n",
    "plt.scatter(all_X, all_Y, s=18, alpha=0.25, label=\"All schools\")\n",
    "\n",
    "for van in VANS_ORDER:\n",
    "    if van not in all_routes: \n",
    "        continue\n",
    "    path   = all_routes[van][\"path\"]\n",
    "    points = all_routes[van][\"points\"]\n",
    "    col    = color_map.get(van, None)\n",
    "\n",
    "    xs = [points[s][0] for s in path]\n",
    "    ys = [points[s][1] for s in path]\n",
    "    if MAKE_CYCLE and len(path) > 1:\n",
    "        xs = xs + [points[path[0]][0]]\n",
    "        ys = ys + [points[path[0]][1]]\n",
    "\n",
    "    plt.plot(xs, ys, linewidth=2, label=f\"{van} (len={all_routes[van]['length']:.1f})\", color=col)\n",
    "    plt.scatter([points[s][0] for s in path], [points[s][1] for s in path], s=30, color=col)\n",
    "    for i, s in enumerate(path, start=1):\n",
    "        plt.text(points[s][0], points[s][1], f\"{s}\\n#{i}\", fontsize=8, color=col)\n",
    "\n",
    "plt.xlabel(\"X\"); plt.ylabel(\"Y\")\n",
    "plt.title(\"Both Vans - Shortest Routes (Combined)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "combined_png = OUT_DIR / \"fig_routes_combined.png\"\n",
    "plt.savefig(combined_png, dpi=160, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"Saved combined figure:\", combined_png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
