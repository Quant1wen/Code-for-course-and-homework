{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "927fd82f",
   "metadata": {},
   "source": [
    "**Problem 1**\\\n",
    "Full solution for problem1"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Data clean\\\n",
    "Run in the same folder with the original data."
   ],
   "id": "6fe662c81b1ba92c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837b28ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0474c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "income = pd.read_csv('avg_individual_income.csv')\n",
    "employ = pd.read_csv('employment_rate.csv')\n",
    "population = pd.read_csv('population.csv')\n",
    "facility = pd.read_csv('child_care_regulated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38907882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_zip(df, candidates=('zipcode', 'zip_code', 'ZIP code', 'ZIP', 'Zip')):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            df = df.rename(columns={c: 'zipcode'})\n",
    "            break\n",
    "    df['zipcode'] = (\n",
    "        df['zipcode']\n",
    "        .astype(str)\n",
    "        .str.extract(r'(\\d+)', expand=False)\n",
    "        .str.zfill(5)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def _zpad(x):\n",
    "    return (\n",
    "        pd.Series(x)\n",
    "        .astype(str)\n",
    "        .str.extract(r'(\\d+)', expand=False)\n",
    "        .str.zfill(5)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3147c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "income = standardize_zip(income)\n",
    "employ = standardize_zip(employ)\n",
    "population = standardize_zip(population)\n",
    "facility = standardize_zip(facility)\n",
    "\n",
    "# early-child capacity = infant + toddler + preschool\n",
    "facility['early_child_capacity'] = facility[\n",
    "    ['infant_capacity', 'toddler_capacity', 'preschool_capacity']\n",
    "].sum(axis=1)\n",
    "\n",
    "fac_caps = (\n",
    "    facility\n",
    "    .groupby('zipcode', as_index=False)\n",
    "    .agg(\n",
    "        total_capacity=('total_capacity', 'sum'),\n",
    "        early_child_capacity=('early_child_capacity', 'sum')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17c3faee",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_0_5_col = '-5'\n",
    "age_5_9_col = '5-9'\n",
    "age_10_14_col = '10-14'\n",
    "\n",
    "population['pop_0_5'] = population[age_0_5_col]\n",
    "population['pop_0_12'] = (\n",
    "    population[age_0_5_col] +\n",
    "    population[age_5_9_col] +\n",
    "    (3/5) * population[age_10_14_col]\n",
    ")\n",
    "\n",
    "pop_sel = population[['zipcode', 'pop_0_5', 'pop_0_12']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19ecd3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = (\n",
    "    fac_caps\n",
    "    .merge(pop_sel, on='zipcode', how='left')\n",
    "    .merge(income.drop_duplicates('zipcode'), on='zipcode', how='left')\n",
    "    .merge(employ.drop_duplicates('zipcode'), on='zipcode', how='left')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f578c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a working df\n",
    "df = merged.copy()\n",
    "df['zipcode'] = _zpad(df['zipcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bd62537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename capacity columns to 0_5 and 0_12\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        'early_child_capacity': '0_5_capacity',\n",
    "        'total_capacity': '0_12_capacity'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15e7baba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facility table capacities consistent with naming\n",
    "facility = facility.rename(\n",
    "    columns={\n",
    "        'total_capacity': '0_12_capacity',\n",
    "        'early_child_capacity': '0_5_capacity'\n",
    "    }\n",
    ")\n",
    "# Keep only rows with population available\n",
    "df = df.dropna(subset=['pop_0_5', 'pop_0_12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46f2aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High demand flag\n",
    "# (column names must match your CSVs; adjust if needed)\n",
    "df['high_demand'] = (\n",
    "    (df['employment rate'] >= 0.6) | (df['average income'] <= 60000)\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6abf7988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing objects\n",
    "Z_all = df['zipcode'].tolist()\n",
    "zip_now_012 = df.set_index('zipcode')['0_12_capacity'].fillna(0.0).to_dict()\n",
    "zip_now_05 = df.set_index('zipcode')['0_5_capacity'].fillna(0.0).to_dict()\n",
    "pop_012 = df.set_index('zipcode')['pop_0_12'].to_dict()\n",
    "pop_05 = df.set_index('zipcode')['pop_0_5'].to_dict()\n",
    "is_hd = df.set_index('zipcode')['high_demand'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "481a3d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facility-level expansion caps: min(120% of its capacity, 500)\n",
    "fac_012 = facility['0_12_capacity'].fillna(0.0)\n",
    "facility['exp_cap_fac'] = np.minimum(1.2 * fac_012, 500.0)\n",
    "# Zip-level total expansion cap (sum of facility caps in the zip) — not used directly as a constraint here,\n",
    "# but kept if you want to audit\n",
    "exp_cap_zip = facility.groupby('zipcode', as_index=False)['exp_cap_fac'].sum()\n",
    "exp_cap_zip = dict(zip(exp_cap_zip['zipcode'], exp_cap_zip['exp_cap_fac']))\n",
    "for z in Z_all:\n",
    "    exp_cap_zip.setdefault(z, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c196add4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New facility types\n",
    "NEW_TYPES = {\n",
    "    'S': {'tot': 100, 'u5max': 50,  'cost':  65000},\n",
    "    'M': {'tot': 200, 'u5max': 100, 'cost':  95000},\n",
    "    'L': {'tot': 400, 'u5max': 200, 'cost': 115000},\n",
    "}\n",
    "# cost per 0-5 slot\n",
    "EQUIP_COST_U5 = 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b333019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize facility-level info arrays\n",
    "facility = facility.copy()\n",
    "facility['cap_now'] = facility['0_12_capacity'].fillna(0.0)\n",
    "facility['cap_add_max'] = facility['exp_cap_fac'].fillna(0.0)\n",
    "# facility match\n",
    "fac_by_zip = {}\n",
    "for z, grp in facility.groupby('zipcode'):\n",
    "    fac_by_zip[z] = {\n",
    "        'idx':  grp.index.to_list(),\n",
    "        'n_now': grp['cap_now'].to_numpy(dtype=float),\n",
    "        'x_max': grp['cap_add_max'].to_numpy(dtype=float),\n",
    "    }\n",
    "for z in Z_all:\n",
    "    fac_by_zip.setdefault(z, {'idx': [], 'n_now': np.zeros(0), 'x_max': np.zeros(0)})"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "2. Parameter builder\\\n",
    "Add parameters for building and expansion.\\\n",
    "Including the upper bound for each zipcode."
   ],
   "id": "df806c1c5328fbb1"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3138b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_builds(z):\n",
    "    \"\"\"A small heuristic UB on new builds to tighten the model.\"\"\"\n",
    "    thr = 0.5 if is_hd[z] == 1 else (1.0/3.0)\n",
    "    need_tot = max(thr * pop_012[z] - zip_now_012[z], 0.0)\n",
    "    need_u5 = max((2.0/3.0) * pop_05[z] - zip_now_05[z], 0.0)\n",
    "\n",
    "    need_by_tot = math.ceil(need_tot / 100.0) if need_tot > 0 else 0\n",
    "    need_by_u5  = math.ceil(need_u5  /  50.0) if need_u5  > 0 else 0\n",
    "\n",
    "    base = max(need_by_tot, need_by_u5)\n",
    "    if base == 0:\n",
    "        return 0, 0, 0\n",
    "    ub = base + 3\n",
    "    ub = int(min(ub, 30))\n",
    "    return ub, ub, ub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ca4a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time limited detection\n",
    "def _make_model(name='p1_statewide', mipgap=1e-4, time_limit=None, verbose=False):\n",
    "    m = gp.Model(name)\n",
    "    m.Params.MIPGap = mipgap\n",
    "    if time_limit is not None:\n",
    "        m.Params.TimeLimit = time_limit\n",
    "    if not verbose:\n",
    "        m.Params.OutputFlag = 0\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "826309ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_facility_expansion_vars(m, facility_df, eps=1e-6):\n",
    "    \"\"\"Add expansion variables per facility:\n",
    "       x_fac[f] = expansion slots (continuous, 0..x_max)\n",
    "       y_trig[f] = 1 if expansion >= 100% of existing capacity (cap_now), else 0\n",
    "    \"\"\"\n",
    "    fac_idx = facility_df.index.to_list()\n",
    "    fac_zip = facility_df['zipcode'].tolist()\n",
    "    cap_now = facility_df['cap_now'].fillna(0.0).to_numpy(dtype=float)\n",
    "    cap_add_max = facility_df['cap_add_max'].fillna(0.0).to_numpy(dtype=float)\n",
    "\n",
    "    x_f, y_f = {}, {}\n",
    "    for k, f in enumerate(fac_idx):\n",
    "        x = m.addVar(lb=0.0, ub=float(cap_add_max[k]), name=f'x_fac[{f}]')\n",
    "        y = m.addVar(vtype=GRB.BINARY, name=f'y_trig[{f}]')\n",
    "\n",
    "        if cap_now[k] > 0:\n",
    "            # y=1 ⇒ x >= cap_now - eps\n",
    "            m.addGenConstrIndicator(y, True,  x, GRB.GREATER_EQUAL, cap_now[k] - eps, name=f'trig_on[{f}]')\n",
    "            # y=0 ⇒ x <= cap_now - eps\n",
    "            m.addGenConstrIndicator(y, False, x, GRB.LESS_EQUAL,   cap_now[k] - eps, name=f'trig_off[{f}]')\n",
    "        else:\n",
    "            # No existing capacity ⇒ cannot trigger the '≥100%' rule\n",
    "            m.addConstr(y == 0, name=f'no_trig_nf0[{f}]')\n",
    "        x_f[f] = x\n",
    "        y_f[f] = y\n",
    "    return fac_idx, fac_zip, cap_now, cap_add_max, x_f, y_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35223bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_zip_level_vars(m, Z_all, is_hd, max_builds, NEW_TYPES):\n",
    "    \"\"\"Add zip-level new build counts and two U5 allocation auxiliaries.\"\"\"\n",
    "    nS, nM, nL, b05, e05, thr_zip = {}, {}, {}, {}, {}, {}\n",
    "    for z in Z_all:\n",
    "        thr_zip[z] = 0.5 if is_hd[z] == 1 else (1.0/3.0)\n",
    "        ubS, ubM, ubL = max_builds(z)\n",
    "\n",
    "        nS[z] = m.addVar(vtype=GRB.INTEGER, lb=0, ub=ubS, name=f'nS[{z}]')\n",
    "        nM[z] = m.addVar(vtype=GRB.INTEGER, lb=0, ub=ubM, name=f'nM[{z}]')\n",
    "        nL[z] = m.addVar(vtype=GRB.INTEGER, lb=0, ub=ubL, name=f'nL[{z}]')\n",
    "\n",
    "        # b05 = new-build U5 slots; e05 = expansion-allocated U5 slots\n",
    "        b05[z] = m.addVar(lb=0.0, name=f'b05[{z}]')\n",
    "        e05[z] = m.addVar(lb=0.0, name=f'e05[{z}]')\n",
    "    return nS, nM, nL, b05, e05, thr_zip"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "3. Constraints\\\n",
    "Build constraints on:\n",
    "1. 0-12 threshold for different demand zipcode.\n",
    "2. 0-5 threshold for each zipcode as NYS requirement\n",
    "3. 0-5 threshold as it cannot exceed the 0-12 additional slot\n",
    "4. Maximum expansion scale is the minimum of 1.2 scale and 500 addition slots."
   ],
   "id": "6970686ecdeacd2f"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3578d54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_linking_constraints(m, Z_all, fac_idx, fac_zip, x_f, e05, b05, nS, nM, nL, NEW_TYPES):\n",
    "    \"\"\"Link e05 to expansions in the zip; bound b05 by new build U5 maxima.\"\"\"\n",
    "    facs_in_zip = defaultdict(list)\n",
    "    for f, zf in zip(fac_idx, fac_zip):\n",
    "        facs_in_zip[zf].append(f)\n",
    "\n",
    "    # e05[z] can’t exceed total expansion in zip z\n",
    "    for z in Z_all:\n",
    "        sum_xz = gp.quicksum(x_f[f] for f in facs_in_zip[z]) if len(facs_in_zip[z]) > 0 else gp.LinExpr(0.0)\n",
    "        m.addConstr(e05[z] <= sum_xz + 1e-9, name=f'u5_subset[{z}]')\n",
    "\n",
    "    # b05[z] bounded by the sum of U5 caps of newly built centers\n",
    "    for z in Z_all:\n",
    "        m.addConstr(\n",
    "            b05[z] <= NEW_TYPES['S']['u5max'] * nS[z]\n",
    "                    + NEW_TYPES['M']['u5max'] * nM[z]\n",
    "                    + NEW_TYPES['L']['u5max'] * nL[z],\n",
    "            name=f'build05_cap[{z}]'\n",
    "        )\n",
    "    return facs_in_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "065a9091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coverage_constraints(\n",
    "    m, Z_all, thr_zip, pop_012, pop_05, zip_now_012, zip_now_05,\n",
    "    facs_in_zip, x_f, nS, nM, nL, e05, b05, NEW_TYPES\n",
    "):\n",
    "    \"\"\"Zip-level coverage constraints for 0–12 and under-5 populations.\"\"\"\n",
    "    for z in Z_all:\n",
    "        tot_after = (\n",
    "            zip_now_012[z]\n",
    "            + gp.quicksum(x_f[f] for f in facs_in_zip[z])\n",
    "            + NEW_TYPES['S']['tot'] * nS[z]\n",
    "            + NEW_TYPES['M']['tot'] * nM[z]\n",
    "            + NEW_TYPES['L']['tot'] * nL[z]\n",
    "        )\n",
    "        u5_after = zip_now_05[z] + e05[z] + b05[z]\n",
    "\n",
    "        m.addConstr(tot_after >= thr_zip[z] * pop_012[z], name=f'cover_012[{z}]')\n",
    "        m.addConstr(u5_after >= (2.0 / 3.0) * pop_05[z], name=f'cover_05[{z}]')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Objective Function",
   "id": "5c80f69c8fd73ebb"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc0e81d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_objective(\n",
    "    m, fac_idx, cap_now, x_f, y_f,\n",
    "    Z_all, e05, b05, nS, nM, nL, NEW_TYPES, EQUIP_COST_U5\n",
    "):\n",
    "    \"\"\"Objective with BOTH:\n",
    "       (i) $200 per expansion slot (for all x_f) AND\n",
    "       (ii) threshold cost when expansion ≥100%: $20,000 + $200 * cap_now\n",
    "       plus U5 equipment and new build costs.\n",
    "    \"\"\"\n",
    "    # Threshold (≥100%) expansion cost per facility\n",
    "    expand_trigger_cost = gp.quicksum(\n",
    "        (20000.0 + 200.0 * cap_now[k]) * y_f[f]\n",
    "        for k, f in enumerate(fac_idx)\n",
    "    )\n",
    "\n",
    "    # Per-slot expansion cost\n",
    "    additional_cost = 0.0\n",
    "    expand_per_slot_cost = gp.quicksum(\n",
    "        additional_cost * x_f[f] for f in fac_idx\n",
    "    )\n",
    "\n",
    "    # U5 equipment cost: $100 per new U5 slot (expansion e05 + new build b05)\n",
    "    equip_cost = EQUIP_COST_U5 * (\n",
    "        gp.quicksum(e05[z] for z in Z_all) +\n",
    "        gp.quicksum(b05[z] for z in Z_all)\n",
    "    )\n",
    "\n",
    "    # New build cost\n",
    "    build_cost = gp.quicksum(\n",
    "        NEW_TYPES['S']['cost'] * nS[z] +\n",
    "        NEW_TYPES['M']['cost'] * nM[z] +\n",
    "        NEW_TYPES['L']['cost'] * nL[z]\n",
    "        for z in Z_all\n",
    "    )\n",
    "\n",
    "    m.setObjective(\n",
    "        expand_trigger_cost + expand_per_slot_cost + equip_cost + build_cost,\n",
    "        GRB.MINIMIZE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99bbb75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_and_collect_fac(m, status_ok_set, fac_idx, fac_zip, cap_now, cap_add_max, x_f, y_f):\n",
    "    status = (\n",
    "        'optimal' if m.Status == GRB.OPTIMAL\n",
    "        else ('time_limit' if m.Status == GRB.TIME_LIMIT else f'status_{m.Status}')\n",
    "    )\n",
    "    obj = m.objVal if m.Status in status_ok_set else None\n",
    "\n",
    "    fac_rows = []\n",
    "    for k, f in enumerate(fac_idx):\n",
    "        fac_rows.append({\n",
    "            'facility_id': f,\n",
    "            'zipcode': fac_zip[k],\n",
    "            'cap_now': cap_now[k],\n",
    "            'cap_add_max': cap_add_max[k],\n",
    "            'expand_x': float(x_f[f].X) if obj is not None else None,\n",
    "            'trigger_100pct': int(round(y_f[f].X)) if obj is not None else None\n",
    "        })\n",
    "    df_fac = pd.DataFrame(fac_rows)\n",
    "    return status, obj, df_fac"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Outcome summary function",
   "id": "a37ea0b17ef991ed"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0575e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_zip_summary(\n",
    "    df_fac, Z_all, thr_zip, zip_now_012, zip_now_05,\n",
    "    pop_012, pop_05, NEW_TYPES, EQUIP_COST_U5,\n",
    "    nS, nM, nL, b05, e05, obj\n",
    "):\n",
    "    zip_rows = []\n",
    "    for z in Z_all:\n",
    "        pre_012, pre_05 = zip_now_012[z], zip_now_05[z]\n",
    "\n",
    "        build_S_z = int(round(nS[z].X)) if obj is not None else None\n",
    "        build_M_z = int(round(nM[z].X)) if obj is not None else None\n",
    "        build_L_z = int(round(nL[z].X)) if obj is not None else None\n",
    "        build_05_z = b05[z].X if obj is not None else None\n",
    "\n",
    "        build_scale_z = (\n",
    "            100 * build_S_z + 200 * build_M_z + 400 * build_L_z\n",
    "        ) if obj is not None else None\n",
    "\n",
    "        exp_012_z = df_fac.loc[df_fac['zipcode'] == z, 'expand_x'].sum() if obj is not None else None\n",
    "        exp_05_z = e05[z].X if obj is not None else None\n",
    "\n",
    "        after_012 = (pre_012 + exp_012_z + build_scale_z) if obj is not None else None\n",
    "        after_05 = (pre_05 + exp_05_z + build_05_z) if obj is not None else None\n",
    "\n",
    "        target_012 = thr_zip[z] * pop_012[z] if obj is not None else None\n",
    "        target_05 = (2.0 / 3.0) * pop_05[z] if obj is not None else None\n",
    "\n",
    "        tol = 1e-6\n",
    "        meet_012 = (after_012 is not None) and (after_012 >= target_012 - tol)\n",
    "        meet_05 = (after_05 is not None) and (after_05 >= target_05 - tol)\n",
    "        gap_012 = max(target_012 - after_012, 0.0) if obj is not None else None\n",
    "        gap_05 = max(target_05 - after_05, 0.0) if obj is not None else None\n",
    "\n",
    "        # Threshold expansion cost (≥100% trigger)\n",
    "        fac_expand_trig_cost_z = (\n",
    "            df_fac.loc[df_fac['zipcode'] == z, :]\n",
    "            .assign(\n",
    "                trig_cost=lambda d: (20000.0 + 200.0 * d['cap_now']) * d['trigger_100pct']\n",
    "            )['trig_cost'].sum() if obj is not None else None\n",
    "        )\n",
    "\n",
    "        # Per-slot expansion cost ($200 per expansion slot)\n",
    "        fac_expand_slot_cost_z = (\n",
    "            200.0 * df_fac.loc[df_fac['zipcode'] == z, 'expand_x'].sum()\n",
    "        ) if obj is not None else None\n",
    "\n",
    "        equip_cost_z = EQUIP_COST_U5 * (\n",
    "            (exp_05_z if obj is not None else 0.0) +\n",
    "            (build_05_z if obj is not None else 0.0)\n",
    "        )\n",
    "        build_cost_z = (\n",
    "            NEW_TYPES['S']['cost'] * build_S_z +\n",
    "            NEW_TYPES['M']['cost'] * build_M_z +\n",
    "            NEW_TYPES['L']['cost'] * build_L_z\n",
    "        ) if obj is not None else None\n",
    "\n",
    "        obj_z = (\n",
    "            fac_expand_trig_cost_z +\n",
    "            fac_expand_slot_cost_z +\n",
    "            equip_cost_z +\n",
    "            build_cost_z\n",
    "        ) if obj is not None else None\n",
    "\n",
    "        zip_rows.append({\n",
    "            'zipcode': z,\n",
    "            'obj_zip': obj_z,\n",
    "            'base_012': pre_012, 'base_05': pre_05,\n",
    "            'exp_012_zip': exp_012_z, 'exp_05_zip': exp_05_z,\n",
    "            'build_scale_zip': build_scale_z,\n",
    "            'build_S': build_S_z, 'build_M': build_M_z, 'build_L': build_L_z, 'build_05': build_05_z,\n",
    "            'after_012': after_012, 'after_05': after_05,\n",
    "            'target_012': target_012, 'target_05': target_05,\n",
    "            'meet_012': int(bool(meet_012)), 'meet_05': int(bool(meet_05)),\n",
    "            'gap_012': gap_012, 'gap_05': gap_05,\n",
    "            'thr_used_012': thr_zip[z]\n",
    "        })\n",
    "\n",
    "    df_zip = pd.DataFrame(zip_rows).sort_values('zipcode')\n",
    "    df_builds = df_zip[['zipcode', 'build_S', 'build_M', 'build_L', 'build_05', 'build_scale_zip']].copy()\n",
    "    return df_zip, df_builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80bbdb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_outputs(outdir, status, obj, df_zip, df_fac, df_builds):\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    with open(os.path.join(outdir, 'overall_objective.txt'), 'w') as f:\n",
    "        f.write(f\"status: {status}\\n\")\n",
    "        f.write(f\"objective: {obj}\\n\")\n",
    "    df_zip.to_csv(os.path.join(outdir, 'zip_summary.csv'), index=False)\n",
    "    df_fac.to_csv(os.path.join(outdir, 'facility_expansion.csv'), index=False)\n",
    "    df_builds.to_csv(os.path.join(outdir, 'zip_builds.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18a16d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _minmax(df):\n",
    "    return (df - df.min()) / (df.max() - df.min() + 1e-9)\n",
    "\n",
    "def _plot_heatmap(matrix, row_labels, col_labels, title, out_path):\n",
    "    plt.figure(figsize=(max(6, 0.4*len(col_labels)), max(6, 0.3*len(row_labels))))\n",
    "    im = plt.imshow(matrix, aspect='auto', interpolation='nearest')\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    plt.title(title)\n",
    "    plt.xticks(ticks=np.arange(len(col_labels)), labels=col_labels, rotation=45, ha='right')\n",
    "    plt.yticks(ticks=np.arange(len(row_labels)), labels=row_labels)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "def make_heatmaps(outdir, df_zip, df_fac, top_k_zip=40, top_k_fac=40,\n",
    "                  zip_metric='gap_012', fac_metric='expand_x'):\n",
    "    # ---------- ZIP-level ----------\n",
    "    if df_zip is not None and not df_zip.empty and zip_metric in df_zip.columns:\n",
    "        cols_zip = [c for c in [\n",
    "            'base_012','target_012','after_012',\n",
    "            'base_05','target_05','after_05',\n",
    "            'exp_012_zip','exp_05_zip','build_scale_zip','build_05',\n",
    "            \n",
    "        ] if c in df_zip.columns]\n",
    "\n",
    "        top_zip = (df_zip\n",
    "                   .replace([np.inf, -np.inf], np.nan)\n",
    "                   .fillna(0)\n",
    "                   .sort_values(zip_metric, ascending=False)\n",
    "                   .head(top_k_zip)\n",
    "                  ).copy()\n",
    "\n",
    "        data_zip = top_zip[cols_zip].copy()\n",
    "        data_zip_norm = _minmax(data_zip)\n",
    "\n",
    "        row_labels = top_zip['zipcode'].astype(str).tolist()\n",
    "        _plot_heatmap(\n",
    "            data_zip_norm.to_numpy(),\n",
    "            row_labels=row_labels,\n",
    "            col_labels=cols_zip,\n",
    "            title=f'ZIP Heatmap (Top {top_k_zip} by {zip_metric})',\n",
    "            out_path=os.path.join(outdir, f'heatmap_zip_top{top_k_zip}_{zip_metric}.png')\n",
    "        )\n",
    "\n",
    "    # Facility level output\n",
    "    if df_fac is not None and not df_fac.empty and fac_metric in df_fac.columns:\n",
    "        df_fac = df_fac.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "        cols_fac = [c for c in [\n",
    "            'cap_now','cap_add_max','expand_x','expand_ratio'\n",
    "        ] if c in df_fac.columns]\n",
    "\n",
    "        top_fac = (df_fac\n",
    "                   .sort_values(fac_metric, ascending=False)\n",
    "                   .head(top_k_fac)\n",
    "                  ).copy()\n",
    "\n",
    "        if 'facility_id' in top_fac.columns and 'zipcode' in top_fac.columns:\n",
    "            row_labels = (top_fac['zipcode'].astype(str) + '#' + top_fac['facility_id'].astype(str)).tolist()\n",
    "        else:\n",
    "            row_labels = [str(i) for i in top_fac.index.tolist()]\n",
    "\n",
    "        data_fac = top_fac[cols_fac].copy()\n",
    "        data_fac_norm = _minmax(data_fac)\n",
    "\n",
    "        _plot_heatmap(\n",
    "            data_fac_norm.to_numpy(),\n",
    "            row_labels=row_labels,\n",
    "            col_labels=cols_fac,\n",
    "            title=f'Facility Heatmap (Top {top_k_fac} by {fac_metric})',\n",
    "            out_path=os.path.join(outdir, f'heatmap_fac_top{top_k_fac}_{fac_metric}.png')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af3056e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_statewide(mipgap=1e-4, time_limit=None, verbose=False, outdir='outputs_problem1'):\n",
    "    m = _make_model(mipgap=mipgap, time_limit=time_limit, verbose=verbose)\n",
    "\n",
    "    fac_idx, fac_zip, cap_now, cap_add_max, x_f, y_f = add_facility_expansion_vars(m, facility)\n",
    "    nS, nM, nL, b05, e05, thr_zip = add_zip_level_vars(m, Z_all, is_hd, max_builds, NEW_TYPES)\n",
    "    facs_in_zip = add_linking_constraints(m, Z_all, fac_idx, fac_zip, x_f, e05, b05, nS, nM, nL, NEW_TYPES)\n",
    "\n",
    "    add_coverage_constraints(\n",
    "        m, Z_all, thr_zip, pop_012, pop_05, zip_now_012, zip_now_05,\n",
    "        facs_in_zip, x_f, nS, nM, nL, e05, b05, NEW_TYPES\n",
    "    )\n",
    "\n",
    "    set_objective(\n",
    "        m, fac_idx, cap_now, x_f, y_f,\n",
    "        Z_all, e05, b05, nS, nM, nL, NEW_TYPES, EQUIP_COST_U5\n",
    "    )\n",
    "\n",
    "    m.optimize()\n",
    "\n",
    "    status_ok_set = {GRB.OPTIMAL, GRB.TIME_LIMIT}\n",
    "    status, obj, df_fac = optimize_and_collect_fac(\n",
    "        m, status_ok_set, fac_idx, fac_zip, cap_now, cap_add_max, x_f, y_f\n",
    "    )\n",
    "\n",
    "    df_zip, df_builds = build_zip_summary(\n",
    "        df_fac, Z_all, thr_zip, zip_now_012, zip_now_05,\n",
    "        pop_012, pop_05, NEW_TYPES, EQUIP_COST_U5,\n",
    "        nS, nM, nL, b05, e05, obj\n",
    "    )\n",
    "\n",
    "    write_outputs(outdir, status, obj, df_zip, df_fac, df_builds)\n",
    "    make_heatmaps(outdir, df_zip, df_fac, top_k_zip=40, top_k_fac=40,\n",
    "              zip_metric='gap_012', fac_metric='expand_x')\n",
    "\n",
    "    return {\n",
    "        'status': status,\n",
    "        'objective': obj,\n",
    "        'df_zip': df_zip,\n",
    "        'df_fac': df_fac,\n",
    "        'df_builds': df_builds\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7073b696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2722020\n",
      "Academic license - for non-commercial use only - expires 2026-10-14\n",
      "Set parameter MIPGap to value 0.0001\n",
      "Status: optimal\n",
      "Objective: 177124266.92659706\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    res = solve_statewide(mipgap=1e-4, time_limit=None, verbose=False, outdir='outputs_problem1')\n",
    "    print(\"Status:\", res['status'])\n",
    "    print(\"Objective:\", res['objective'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
